# -*- coding: utf-8 -*-
"""Dicoding_JayaJayaMaju

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KOkl7JU9u2K2HMhEBCLZOPAdzepI2g-S

# Analisa Tingkat Karyawan yang Keluar dari Perusahan Jaya Jaya Maju

Pertanyaan bisnis yang menjawab mengapa tingkat TurnOver perusahaan tinggi:

1. Faktor apa yang paling mempengaruhi atrrition di perusahaan Jaya Jaya Maju?
2. Prediksi Attrition pegawai berdasarkan faktor yang paling mempengaruhi

### Data Gathering
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve,precision_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from scipy.stats import ttest_ind
from google.colab import files
from imblearn.over_sampling import SMOTE

import sklearn
print(sklearn.__version__)

url = 'https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/employee/employee_data.csv'
df = pd.read_csv(url)

df

"""## Data Understanding and Data Wrangling"""

df.info()

df.isnull().sum()

df['Attrition'] = df['Attrition'].fillna(0)

df.info()

df['OverTime'] = df['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)

"""## Data Exploration and Visualization"""

attrition_counts = df['Attrition'].value_counts()
print("Jumlah karyawan yang mengalami attrition:")
print(attrition_counts)

unique_values = df['PerformanceRating'].unique()
print("Jenis data yang ada: ",unique_values[0] ," dan",unique_values[1])

unique_values = df['JobInvolvement'].unique()
print("Jenis data yang ada: ",unique_values)

# Membuat facet plot berdasarkan PerformanceRating
g = sns.FacetGrid(df, col='PerformanceRating', hue='Attrition', height=5)
g.map(sns.histplot, 'MonthlyIncome', kde=True)
g.set_titles('PerformanceRating = {col_name}')
g.set_axis_labels('MonthlyIncome', 'Jumlah')
g.add_legend(title='Attrition')
plt.show()

sns.countplot(data=df, x='JobInvolvement', hue='Attrition')
plt.title('Hubungan Antara JobInvolvement dan Attrition')
plt.xlabel('JobInvolvement')
plt.ylabel('Jumlah')
plt.show()

plt.figure(figsize=(15, 5))
df_attrition_1 = df[df['Attrition'] == 1]
# Subplot pertama: countplot OverTime
plt.subplot(1, 2, 1)
sns.countplot(data=df_attrition_1, x='OverTime')
plt.title('Jumlah Karyawan dengan Attrition = 1 berdasarkan Overtime')
plt.xlabel('OverTime')
plt.ylabel('Jumlah')

# Subplot kedua: countplot EnvironmentSatisfaction
plt.subplot(1, 2, 2)
sns.countplot(data=df_attrition_1, x='EnvironmentSatisfaction')
plt.title('Jumlah Karyawan dengan Attrition = 1 berdasarkan EnvironmentSatisfaction')
plt.xlabel('EnvironmentSatisfaction')
plt.ylabel('Jumlah')

plt.tight_layout()
plt.show()

sns.pairplot(df[['MonthlyIncome', 'PercentSalaryHike', 'YearsAtCompany', 'Attrition']], hue='Attrition')
plt.show()

df_attrition_1 = df[df['Attrition'] == 1]

# Hitung jumlah karyawan untuk setiap 'JobRole'
jobrole_counts = df_attrition_1['JobRole'].value_counts()

top_5_jobroles = jobrole_counts.nlargest(5)

# Buat diagram lingkaran
plt.pie(top_5_jobroles, labels=top_5_jobroles.index, autopct='%1.1f%%', startangle=140)
plt.title('Top 5 Job Roles that Have the Most Attrition Rate')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

sns.boxplot(data=df, x='JobRole', y='MonthlyIncome')
plt.title('Box Plot dari MonthlyIncome berdasarkan JobRole')
plt.xlabel('JobRole')
plt.ylabel('MonthlyIncome')
plt.xticks(rotation=90)
plt.show()

overtime_count = df[df['OverTime'] == 1].groupby('JobRole').size().reset_index(name='OvertimeYesCount')

# Menampilkan JobRole dengan jumlah Overtime 'Yes' terbanyak
top_overtime_jobrole = overtime_count.sort_values(by='OvertimeYesCount', ascending=False).iloc[0]

print("JobRole dengan jumlah Overtime 'Yes' terbanyak:")
print(top_overtime_jobrole)

sns.lineplot(data=df, x='YearsAtCompany', y='PercentSalaryHike', hue='Attrition')
plt.title('Line Plot antara YearsAtCompany dan PercentSalaryHike')
plt.xlabel('YearsAtCompany')
plt.ylabel('PercentSalaryHike')
plt.show()

sns.boxplot(data=df, x='Attrition', y='JobSatisfaction')
plt.title('Box Plot dari JobSatisfaction berdasarkan Attrition')
plt.xlabel('Attrition')
plt.ylabel('JobSatisfaction')
plt.show()

attrition_stats = df.groupby('Attrition')['MonthlyIncome'].describe()
print("Descriptive statistics for MonthlyIncome by Attrition:")
print(attrition_stats)

# Visualization
plt.figure(figsize=(12, 6))

# Boxplot
plt.subplot(1, 2, 1)
sns.boxplot(x='Attrition', y='MonthlyIncome', data=df)
plt.title('Boxplot of MonthlyIncome by Attrition')

# Histogram
plt.subplot(1, 2, 2)
sns.histplot(df[df['Attrition'] == 0]['MonthlyIncome'], kde=True, color='blue', label='No Attrition')
sns.histplot(df[df['Attrition'] == 1]['MonthlyIncome'], kde=True, color='red', label='Attrition')
plt.title('Histogram of MonthlyIncome by Attrition')
plt.legend()

plt.tight_layout()
plt.show()

# Statistical test
attrition_income = df[df['Attrition'] == 1]['MonthlyIncome']
no_attrition_income = df[df['Attrition'] == 0]['MonthlyIncome']

t_stat, p_value = ttest_ind(attrition_income, no_attrition_income, equal_var=False)
print(f"T-test: t-statistic = {t_stat}, p-value = {p_value}")

"""## Modelling"""

categorical_columns = ['BusinessTravel', 'Department', 'EducationField']
for column in categorical_columns:
    if column in df.columns:
        label_encoder = LabelEncoder()
        df[column] = label_encoder.fit_transform(df[column])
    else:
        print(f"Column '{column}' not found in the DataFrame")

features = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate',
            'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'NumCompaniesWorked',
            'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',
            'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',
            'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'BusinessTravel',
            'Department', 'EducationField']

missing_features = [feature for feature in features if feature not in df.columns]
if missing_features:
    print(f"Missing features: {missing_features}")
    features = [feature for feature in features if feature in df.columns]

X = df[features]
y = df['Attrition']

scaler = StandardScaler()
X = scaler.fit_transform(X)

# Apply SMOTE to balance the classes
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

initial_model = RandomForestClassifier(random_state=42)
initial_model.fit(X_train, y_train)
initial_feature_importances = pd.Series(initial_model.feature_importances_, index=features)
top_features = initial_feature_importances.nlargest(10).index.tolist()

# Use only the top features for training
X_train_top = X_train[:, [features.index(f) for f in top_features]]
X_test_top = X_test[:, [features.index(f) for f in top_features]]

# Hyperparameter tuning using RandomizedSearchCV with class weights
param_distributions = {
    'n_estimators': [100, 200, 300],
    'max_features': ['sqrt', 'log2'],  # Avoid 'auto' due to deprecation
    'max_depth': [4, 6, 8, 10],
    'criterion': ['gini', 'entropy'],
    'class_weight': ['balanced', 'balanced_subsample']
}

random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),
                                   param_distributions=param_distributions,
                                   n_iter=20,  # Number of parameter settings sampled
                                   cv=3,  # Number of cross-validation folds
                                   n_jobs=-1,  # Use all available CPUs
                                   random_state=42,
                                   scoring='precision')
random_search.fit(X_train_top, y_train)

# Best parameters from RandomizedSearchCV
best_params = random_search.best_params_
print("Best parameters:", best_params)

model = RandomForestClassifier(**best_params, random_state=42)
model.fit(X_train_top, y_train)

y_pred = model.predict(X_test_top)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

precision = precision_score(y_test, y_pred, average=None)
print("Precision for class 0:", precision[0])
print("Precision for class 1:", precision[1])

# Feature Importances
feature_importances = pd.Series(model.feature_importances_, index=top_features)
plt.figure(figsize=(10, 6))
feature_importances.nlargest(10).plot(kind='barh')
plt.title('Top 10 Feature Importance')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

"""## Evaluation"""

# Plot confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Plot ROC curve
y_prob = model.predict_proba(X_test_top)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()